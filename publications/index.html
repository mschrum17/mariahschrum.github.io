<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Rohan Paleja | Publications</title>
  <meta name="description" content="A beautiful Jekyll theme for academics">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Rohan</span> Paleja</a>
     	<div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center" style="line-height: 1em;">
            <a href="mailto:rpaleja3@gatech.edu"><i class="fa fa-envelope-square gm-icon"></i></a>
            <a href="https://scholar.google.com/citations?user=xjnQbKgAAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar-square gs-icon"></i></a>
            <a href="https://github.com/rohanpaleja27" target="_blank" title="GitHub"><i class="fab fa-github-square gh-icon"></i></a>
            <a href="https://www.linkedin.com/in/rohan-paleja-6370a3111/" target="_blank" title="LinkedIn"><i class="fab fa-linkedin li-icon"></i></a>
            <a href="https://twitter.com/rohanpaleja27" target="_blank" title="Twitter"><i class="fab fa-twitter-square tw-icon"></i></a>
          </span>
        </div>
 
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
              <li class="nav-item ">
                  <a class="nav-link" href="/assets/pdf/vitae.pdf">
                    Curriculum Vitae
                  </a>
              </li>
           
		          <!-- 
              <li class="nav-item ">
                  <a class="nav-link" href="/projects/">
                    Projects
                    
                  </a>
              </li>
            	-->

              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="/publications/">
                    Publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>
            
<!--              <li class="nav-item ">-->
<!--                  <a class="nav-link" href="/teaching/">-->
<!--                    Teaching-->
<!--                    -->
<!--                  </a>-->
<!--              </li>-->

<!--              <li class="nav-item ">-->
<!--                  <a class="nav-link" href="/service/">-->
<!--                    Service-->
<!--                                        -->
<!--                  </a>-->
<!--              </li>-->
          
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>Publications</h1>
  <h6><nobr><em>*</em></nobr> denotes equal contribution and joint lead authorship.</h6>
  <h6>Blue - Conference Papers.</h6>
  <h6>Red - Workshop and Doctoral Consortia Papers.</h6>
  <h6>Orange - Journal Papers.</h6>


<p><br /></p>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
	

<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://roboticsconference.org/" target="_blank">
          RSS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="paleja2022RSS" class="col p-0">
      <h5 class="title mb-0">Learning Interpretable, High-Performing Policies for Autonomous Driving</h5>
      <div class="author">
                
		
							<nobr><em>Rohan Paleja*</em>,</nobr>
                
                  <nobr><a href="https://yaruniu.com/" target="_blank">Yaru Niu<nobr><em>*</em></nobr></a>,</nobr>

                  <nobr><a href="https://www.andrew-silva.com/" target="_blank">Andrew Silva</a>,</nobr>

                  <nobr><a href="https://www.linkedin.com/in/chace-ritchie" target="_blank">Chace Ritchie</a>,</nobr>

                  <nobr><a href="https://www.linkedin.com/in/sugju-choi" target="_blank">Sugju Choi</a>,</nobr>

									and
                
                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>
        
      </div>

      <div>
        <p class="periodical font-italic">
        Robotics: Science and Systems, 2022
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#paleja2022RSS-abstract" role="button" aria-expanded="false" aria-controls="paleja2022RSS-abstract">Abstract</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/ICCT/2202.02352.pdf" target="_blank">PDF</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/CORE-Robotics-Lab/ICCT" target="_blank">Code</a>
        
      </div>
    
      <div class="col mt-2 p-0">
        <div id="paleja2022RSS-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
	Gradient-based approaches in reinforcement learning have achieved tremendous success in learning policies for autonomous vehicles. While the performance of these approaches warrants real-world adoption, these policies lack interpretability, limiting deployability in the safety-critical and legally-regulated domain of autonomous driving (AD). AD requires interpretable and verifiable control policies that maintain high performance. We propose Interpretable Continuous Control Trees (ICCTs), a tree-based model that can be optimized via modern, gradient-based, RL approaches to produce high-performing, interpretable policies. The key to our approach is a procedure for allowing direct optimization in a sparse decision-tree-like representation. We validate ICCTs against baselines across six domains, showing that ICCTs are capable of learning interpretable policy representations that parity or outperform baselines by up to 33% in AD scenarios while achieving a 300x-600x reduction in the number of policy parameters against deep learning baselines. Furthermore, we demonstrate the interpretability and utility of our ICCTs through a 14-car physical robot demonstration.
	</div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>



<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold pink darken-1 align-middle" style="width: 65px;" href="https://sites.google.com/view/rss22-srl/home" target="_blank">
          RSS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="bobu2022IJRR" class="col p-0">
      <h5 class="title mb-0">Scaling Multi-Agent Reinforcement Learning via State Upsampling</h5>
      <div class="author">
                      <nobr><a href="https://www.luismpimentel.com/" target="_blank">Luis Pimentel<nobr><em>*</em></nobr></a>,</nobr>
									<nobr><em>Rohan Paleja*</em>,</nobr>
              
                  <nobr><a href="https://phejohnwang.github.io/" target="_blank">Zheyuan Wang<nobr></nobr></a>,</nobr>
                
                  <nobr><a href="https://esmaeilseraj09.wixsite.com/home" target="_blank">Esmaeil Seraj</a>,</nobr>
                  <nobr><a href="https://www.linkedin.com/in/james-pagan" target="_blank">James Pagan</a>,</nobr>

									and
                
                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>
        
      </div>

      <div>
        <p class="periodical font-italic">
          RSS 2022 Workshop on Scaling Robot Learning (RSS22-SRL)
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2022IJRR-abstract" role="button" aria-expanded="false" aria-controls="bobu2022IJRR-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/RSS22_SRL_Workshop_Paper_final_accepted.pdf" target="_blank">PDF</a>
          
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="bobu2022IJRR-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
	We consider the problem of scaling Multi-Agent Reinforcement Learning (MARL) algorithms toward larger environments and team sizes. While it is possible to learn a MARL-synthesized policy on these larger problems from scratch, training is difficult as the joint state-action space is much larger. Policy learning will require a large amount of experience (and associated training time) to reach a target performance. In this paper, we propose a transfer learning method that accelerates the training performance in such high-dimensional tasks with increased complexity. Our method upsamples an agent’s state representation in a smaller, less challenging, source task in order to pre-train a target policy for a larger, more challenging, target task. By transferring the policy after pre-training and continuing MARL in the target domain, the information learned within the source task enables higher performance within the target task in significantly less time than training from scratch. As such, our method enables the scalability of coordination problems. Furthermore, as our method only changes the state representation of agents across tasks, it is agnostic to the policy’s architecture and can be deployed across different MARL algorithms. We provide results showing that a policy trained under our method is able to achieve up to a 7.88$\times$ performance improvement under the same amount of training time, compared to a policy trained from scratch. Moreover, our method enables learning in difficult target task settings where training from scratch fails.
	</div>
        </div>
      </div>
      
    </div>
  </div>
</div>
			
</li>

      		<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://aamas2022-conference.auckland.ac.nz/" target="_blank">
          AAMAS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2022ICRA" class="col p-0">
      <h5 class="title mb-0">Learning Efficient Diverse Communication for Cooperative Heterogeneous Teaming </h5>
      <div class="author">

                <nobr><a href="https://esmaeilseraj09.wixsite.com/home" target="_blank">Esmaeil Seraj<nobr><em>*</em></nobr></a>,</nobr>

                  <nobr><a href="https://phejohnwang.github.io/" target="_blank">Zheyuan Wang<nobr><em>*</em></nobr></a>,</nobr>

                          <nobr><em>Rohan Paleja*</em>,</nobr>

                  <nobr><a href="https://www.linkedin.com/in/danielmartin576" target="_blank">Daniel Martin</a>,</nobr>

                  <nobr><a href="https://www.linkedin.com/in/matthew-sklar-422231b4" target="_blank">Matthew Sklar</a>,</nobr>

                  <nobr><a href="https://www.linkedin.com/in/anirudh-patel-7124a1b8" target="_blank">Anirudh Patel</a>,</nobr>

									and

                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
         International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2022
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#paleja2022AAMAS-abstract" role="button" aria-expanded="false" aria-controls="paleja2022AAMAS-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/paleja_hetnet.pdf" target="_blank">PDF</a>
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/nvidia.com/active-concept-learning" target="_blank">Project Website</a>-->

      </div>

      <div class="col mt-2 p-0">
        <div id="paleja2022AAMAS-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
	High-performing teams learn intelligent and efficient communication and coordination strategies to maximize their joint utility. These teams implicitly understand the different roles of heterogeneous team members and adapt their communication protocols accordingly. Multi-Agent Reinforcement Learning (MARL) seeks to develop computational methods for synthesizing such coordination strategies, but formulating models for heterogeneous teams with different state, action, and observation spaces has remained an open problem. Without properly modeling agent heterogeneity, as in prior MARL work that leverages homogeneous graph networks, communication becomes less helpful and can even deteriorate the cooperativity and team performance. We propose Heterogeneous Policy Networks (HetNet) to learn efficient and diverse communication models for coordinating cooperative heterogeneous teams. Building on heterogeneous graph-attention networks, we show that HetNet not only facilitates learning heterogeneous collaborative policies per existing agent-class but also enables end-to-end training for learning highly efficient binarized messaging.
	</div>
        </div>
      </div>

    </div>
  </div>
</div>
</li>



</li>

      		<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold pink darken-1 align-middle" style="width: 65px;" href="https://aamas2022-conference.auckland.ac.nz/" target="_blank">
          AAAI
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2022ICRA" class="col p-0">
      <h5 class="title mb-0">Mutual Understanding in Human-Machine Teaming</h5>
      <div class="author">

                          <nobr><em>Rohan Paleja*</em>,</nobr>

									and

                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
         Association for the Advancement of Artificial Intelligence Conference (AAAI) Doctoral Consortium, 2022
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#paleja2022AAAI-abstract" role="button" aria-expanded="false" aria-controls="paleja2022AAAI-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/AAAI_DC_Rohan_Paleja.pdf target="_blank">PDF</a>
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/nvidia.com/active-concept-learning" target="_blank">Project Website</a>-->

      </div>

      <div class="col mt-2 p-0">
        <div id="paleja2022AAAI-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
	Collaborative robots (i.e., “cobots”) and machine learning-based virtual agents are increasingly entering the human workspace with the aim of increasing productivity, enhancing safety, and improving the quality of our lives. These agents will dynamically interact with a wide variety of people in dynamic and novel contexts, increasing the prevalence of human-machine teams in healthcare, manufacturing, and search-and-rescue. In this research, we enhance the mutual understanding within a human-machine team by enabling cobots to understand heterogeneous teammates via person-specific embeddings, identifying contexts in which xAI methods can help improve team mental model alignment, and enabling cobots to effectively communicate information that supports high-performance human-machine teaming.
	</div>
        </div>
      </div>

    </div>
  </div>
</div>
</li></ol>

			
			
			</ol>
    </div>
  </div>





<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
	

		<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold orange darken-1 align-middle" style="width: 65px;" href="https://www.tandfonline.com/journals/tciv20" target="_blank">
          CMBBE
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="zurek2021ICRA" class="col p-0">
      <h5 class="title mb-0">Using Machine Learning to Predict Perfusionists Critical Decision-Making during Cardiac Surgery</h5>
      <div class="author">
                
                  <nobr>Roger Dias<nobr><em></em></nobr></a>,</nobr>
		
							<nobr>Marco Zenati,</nobr>
                            <nobr>Geoff Rance,</nobr>
							<nobr>Rithy Srey,</nobr>
							<nobr>David Arney,</nobr>
                  <nobr><a href="http://www.letianchen.me/" target="_blank">Letian Chen</a>,</nobr>
							<nobr><em>Rohan Paleja</em>,</nobr>

                  <nobr><a href="https://scholar.harvard.edu/laurenkennedy-metz/home" target="_blank">Lauren Kennedy-Metz</a>,</nobr>
            
									and
                
                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>
        
      </div>

      <div>
        <p class="periodical font-italic">
        Computer Methods in Biomechanics and Biomedical Engineering, 2021
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#zurek2021ICRA-abstract" role="button" aria-expanded="false" aria-controls="zurek2021ICRA-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.tandfonline.com/doi/abs/10.1080/21681163.2021.2002724?scroll=top&needAccess=true&journalCode=tciv20" target="_blank">PDF</a>
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://youtu.be/A4k3B3uewBs?t=8337" target="_blank">Talk</a>-->
        
      </div>
    
      <div class="col mt-2 p-0">
        <div id="zurek2021ICRA-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
	The cardiac surgery operating room is a high-risk and complex environment in which multiple experts work as a team to provide safe and excellent care to patients. During the cardiopulmonary bypass phase of cardiac surgery, critical decisions need to be made and the perfusionists play a crucial role in assessing available information and taking a certain course of action. In this paper, we report the findings of a simulation-based study using machine learning to build predictive models of perfusionists’ decision-making during critical situations in the operating room (OR). Performing 30-fold cross-validation across 30 random seeds, our machine learning approach was able to achieve an accuracy of 78.2% (95% confidence interval: 77.8% to 78.6%) in predicting perfusionists’ actions, having access to only 148 simulations. The findings from this study may inform future development of computerised clinical decision support tools to be embedded into the OR, improving patient safety and surgical outcomes.
</div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>


		<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://neurips.cc/Conferences/2021/" target="_blank">
          NeurIPS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="sripathy2021ICRA" class="col p-0">
      <h5 class="title mb-0">The Utility of Explainable AI in Ad Hoc Human-Machine Teaming</h5>
      <div class="author">

							<nobr><em>Rohan Paleja*</em>,</nobr>
                
                  <nobr><a href="https://www.linkedin.com/in/muyleng-ghuy" target="_blank">Muyleng Ghuy</a>,</nobr>
                  <nobr><a href="https://www.linkedin.com/in/nadun-ranawaka-arachchige-87701b137" target="_blank">Nadun Ranawaka Arachchige</a>,</nobr>
                  <nobr><a href="https://ilp.mit.edu/node/44597" target="_blank">Reed Jensen</a>,</nobr>
									and
                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>
        
      </div>

      <div>
        <p class="periodical font-italic">
         Conference on Neural Information Processing Systems (NeurIPS), 2021
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#sripathy2021ICRA-abstract" role="button" aria-expanded="false" aria-controls="sripathy2021ICRA-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/the_utility_of_explainable_ai_.pdf" target="_blank">PDF</a>
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arjunsripathy.github.io/model_switching/" target="_blank">Project Website</a>-->
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/arjunsripathy/model_switching" target="_blank">Code</a>-->
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://papertalk.org/papertalks/37000" target="_blank">Talk</a>
        
      </div>
    
      <div class="col mt-2 p-0">
        <div id="sripathy2021ICRA-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
		Recent advances in machine learning have led to growing interest in Explainable AI (xAI) to enable humans to gain insight into the decision-making of machine learning models. Despite this recent interest, the utility of xAI techniques has not yet been characterized in human-machine teaming. Importantly, xAI offers the promise of enhancing team situational awareness (SA) and shared mental model development, which are the key characteristics of effective human-machine teams. Rapidly developing such mental models is especially critical in ad hoc human-machine teaming, where agents do not have a priori knowledge of others’ decision-making strategies. In this paper, we present two novel human-subject experiments quantifying the benefits of deploying xAI techniques within a human-machine teaming scenario. First, we show that xAI techniques can support SA ($p<0.05)$. Second, we examine how different SA levels induced via a collaborative AI policy abstraction affect ad hoc human-machine teaming performance. Importantly, we find that the benefits of xAI are not universal, as there is a strong dependence on the composition of the human-machine team. Novices benefit from xAI providing increased SA ($p<0.05$) but are susceptible to cognitive overhead ($p<0.05$). On the other hand, expert performance degrades with the addition of xAI-based support ($p<0.05$), indicating that the cost of paying attention to the xAI outweighs the benefits obtained from being provided additional information to enhance SA. Our results demonstrate that researchers must deliberately design and deploy the right xAI techniques in the right scenario by carefully considering human-machine team composition and how the xAI method augments SA.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>





	<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold pink darken-1 align-middle" style="width: 65px;" href="https://ai-hri.github.io/2021/" target="_blank">
          AI-HRI
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="bobu2021HRI" class="col p-0">
      <h5 class="title mb-0">Towards Sample-efficient Apprenticeship Learning from Suboptimal Demonstration</h5>
      <div class="author">
                  <nobr><a href="http://www.letianchen.me/" target="_blank">Letian Chen</a>,</nobr>

									<nobr><em>Rohan Paleja</em>,</nobr>

									and
                
                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

        
      </div>

      <div>
        <p class="periodical font-italic">
          AAAI Artificial Intelligence for Human-Robot Interaction (AI-HRI) Fall Symposium, 2021
          <br>
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2021HRI-abstract" role="button" aria-expanded="false" aria-controls="bobu2021HRI-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/SSRR_Extension_AI_HRI-final.pdf" target="_blank">PDF</a>
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/feature-learning" target="_blank">Project Website</a>-->
<!--          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/andreea7b/FERL" target="_blank">Code</a>-->
<!--	  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.youtube.com/watch?v=NaD-eVri8r4&ab_channel=InterACTLab" target="_blank">Talk</a>-->
          
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="bobu2021HRI-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
        Learning from Demonstration (LfD) seeks to democratize robotics by enabling non-roboticist end-users to teach robots to perform novel tasks by providing demonstrations. However, as demonstrators are typically non-experts, modern LfD techniques are unable to produce policies much better than the suboptimal demonstration. A previously-proposed framework, SSRR, has shown success in learning from suboptimal demonstration but relies on noise-injected trajectories to infer an idealized reward function. A random approach such as noise-injection to generate trajectories has two key drawbacks: 1) Performance degradation could be random depending on whether the noise is applied to vital states and 2) Noise-injection generated trajectories may have limited suboptimality and therefore will not accurately represent the whole scope of suboptimality. We present Systematic Self-Supervised Reward Regression, S3RR, to investigate systematic alternatives for trajectory degradation.
	</div>
        </div>
      </div>
      
    </div>
  </div>
</div>



</li>

          <li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://aamas2021.soton.ac.uk/" target="_blank">
          AAMAS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2020HRI" class="col p-0">
      <h5 class="title mb-0">Multi-Agent Graph-Attention Communication and Teaming</h5>
      <div class="author">
                  <nobr><a href="https://yaruniu.com/" target="_blank">Yaru Niu<nobr><em>*</em></nobr></a>,</nobr>

									<nobr><em>Rohan Paleja*</em>,</nobr>


									and

                  <nobr><a href="https://people.eecs.berkeley.edu/~anca/" target="_blank">Anca D. Dragan</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
          International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021
	      <br>
       	<nobr><em style="color:orange;">Best Workshop Paper Award Winner at ICCV MAIR2 Workshop</em></nobr>
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2020HRI-abstract" role="button" aria-expanded="false" aria-controls="bobu2020HRI-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/less/bobu2020HRI.pdf" target="_blank">PDF</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/less-human-decision-model" target="_blank">Project Website</a>
	        <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.youtube.com/watch?v=xa_l5HeyVgw" target="_blank">Talk</a>

      </div>


      <div class="col mt-2 p-0">
        <div id="bobu2020HRI-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Robots need models of human behavior for both inferring human goals and preferences, and predicting what people will do. A common model is the Boltzmann noisily-rational decision model, which assumes people approximately optimize a reward function and choose trajectories in proportion to their exponentiated reward. While this model has been successful in a variety of robotics domains, its roots lie in econometrics, and in modeling decisions among different discrete options, each with its own utility or reward. In contrast, human trajectories lie in a continuous space, with continuous-valued features that influence the reward function. We propose that it is time to rethink the Boltzmann model, and design it from the ground up to operate over such trajectory spaces. We introduce a model that explicitly accounts for distances between trajectories, rather than only their rewards. Rather than each trajectory affecting the decision independently, similar trajectories now affect the decision together. We start by showing that our model better explains human behavior in a user study. We then analyze the implications this has for robot inference, first in toy environments where we have ground truth and find more accurate inference, and finally for a 7DOF robot arm learning from user demonstrations.
          </div>
        </div>
      </div>

    </div>
  </div>
</div>




          <li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://humanrobotinteraction.org/2021/" target="_blank">
          HRI
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2020HRI" class="col p-0">
      <h5 class="title mb-0"> Effects of Social Factors and Team Dynamics on Adoption of Collaborative Robot Autonomy</h5>
      <div class="author">

									<nobr>Mariah Schrum*,</nobr>
									<nobr>Glen Neville*,</nobr>
									<nobr>Michael Johnson*,</nobr>
									<nobr>Nina Moorman,</nobr>
									<nobr><em>Rohan Paleja</em>,</nobr>
									<nobr>Karen Feigh,</nobr>


									and

                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
          ACM/IEEE International Conference on Human Robot Interaction (HRI), 2021
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2020HRI-abstract" role="button" aria-expanded="false" aria-controls="bobu2020HRI-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/less/bobu2020HRI.pdf" target="_blank">PDF</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/less-human-decision-model" target="_blank">Project Website</a>
	        <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.youtube.com/watch?v=xa_l5HeyVgw" target="_blank">Talk</a>

      </div>


      <div class="col mt-2 p-0">
        <div id="bobu2020HRI-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            As automation becomes more prevalent, the fear of job loss due to automation increases. Workers may not be amenable to working with a robotic co-worker due to a negative perception of the technology. The attitudes of workers towards automation are influenced by a variety of complex and multi-faceted factors such as intention to use, perceived usefulness and other external variables. In an analog manufacturing environment, we explore how these various factors influence an individual’s willingness to work with a robot over a human co-worker in a collaborative Lego building task. We specifically explore how this willingness is affected by: 1) the level of social rapport established between the individual and his or her human co-worker, 2) the anthropomorphic qualities of the robot, and 3) factors including trust, fluency and personality traits. Our results show that a participant’s willingness to work with automation decreased due to lower perceived team fluency (p=0.045), rapport established between a participant and their co-worker (p=0.003), the gender of the participant being male (p=0.041), and a higher inherent trust in people (p=0.018).
          </div>
        </div>
      </div>

    </div>
  </div>
</div>
</li>
      </ol>

			
			
			</ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2020</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
		 <li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://www.robot-learning.org/" target="_blank">
          CoRL
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2020HRI" class="col p-0">
      <h5 class="title mb-0">Learning from Suboptimal Demonstration via Self-Supervised Reward Regression</h5>
      <div class="author">

                          <nobr><a href="http://www.letianchen.me/" target="_blank">Letian Chen</a>,</nobr>
							<nobr><em>Rohan Paleja</em>,</nobr>


									and

                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
          Conference on Robot Learning (CoRL), 2021
	      <br>
       	<nobr><em style="color:orange;">Best Paper Award Finalist</em></nobr>
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2020HRI-abstract" role="button" aria-expanded="false" aria-controls="bobu2020HRI-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/less/bobu2020HRI.pdf" target="_blank">PDF</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/less-human-decision-model" target="_blank">Project Website</a>
	        <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.youtube.com/watch?v=xa_l5HeyVgw" target="_blank">Talk</a>

      </div>


      <div class="col mt-2 p-0">
        <div id="bobu2020HRI-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Learning from Demonstration (LfD) seeks to democratize robotics by enabling non-roboticist end-users to teach robots to perform a task by providing a human demonstration. However, modern LfD techniques, e.g. inverse reinforcement learning (IRL), assume users provide at least stochastically optimal demonstrations. This assumption fails to hold in most real-world scenarios. Recent attempts to learn from sub-optimal demonstration leverage pairwise rankings and following the Luce-Shepard rule. However, we show these approaches make incorrect assumptions and thus suffer from brittle, degraded performance. We overcome these limitations in developing a novel approach that bootstraps off suboptimal demonstrations to synthesize optimality-parameterized data to train an idealized reward function. We empirically validate we learn an idealized reward function with ~0.95 correlation with ground-truth reward versus ~0.75 for prior work. We can then train policies achieving ~200% improvement over the suboptimal demonstration and ~90% improvement over prior work. We present a physical demonstration of teaching a robot a topspin strike in table tennis that achieves 32% faster returns and 40% more topspin than user demonstration.
          </div>
        </div>
      </div>

    </div>
  </div>
</div>
</li>
			
<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://neurips.cc" target="_blank">
          NeurIPS
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="bobu2020HRIpioneers" class="col p-0">
      <h5 class="title mb-0">Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations </h5>
      <div class="author">
                
									<nobr><em>Rohan Paleja</em></nobr>
              
      </div>

      <div>
        <p class="periodical font-italic">
          Conference on Neural Information Processing Systems (NeurIPS), 2020.
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2020HRIpioneers-abstract" role="button" aria-expanded="false" aria-controls="bobu2020HRIpioneers-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/lumos/bobu2020HRIpioneers.pdf" target="_blank">PDF</a>
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="bobu2020HRIpioneers-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Resource scheduling and coordination is an NP-hard optimization requiring an efficient allocation of agents to a set of tasks with upper- and lower bound temporal and resource constraints. Due to the large-scale and dynamic nature of resource coordination in hospitals and factories, human domain experts manually plan and adjust schedules on the fly. To perform this job, domain experts leverage heterogeneous strategies and rules-of-thumb honed over years of apprenticeship. What is critically needed is the ability to extract this domain knowledge in a heterogeneous and interpretable apprenticeship learning framework to scale beyond the power of a single human expert, a necessity in safety-critical domains. We propose a personalized and interpretable apprenticeship scheduling algorithm that infers an interpretable representation of all human task demonstrators by extracting decision-making criteria specified by an inferred, personalized embedding without constraining the number of decision-making strategies. We achieve near-perfect LfD accuracy in synthetic domains and 88.22% accuracy on a real-world planning domain, outperforming baselines. Further, a user study conducted shows that our methodology produces both interpretable and highly usable models (p < 0.05).
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>



          <li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold light-blue darken-1 align-middle" style="width: 65px;" href="https://neurips.cc" target="_blank">
          HRI
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2020HRIpioneers" class="col p-0">
      <h5 class="title mb-0">Joint Goal and Strategy Inference across Heterogeneous Demonstrators via Reward Network Distillation  </h5>
      <div class="author">

									<nobr><em>Rohan Paleja</em></nobr>

      </div>

      <div>
        <p class="periodical font-italic">
          ACM/IEEE International Conference on Human Robot Interaction (HRI), 2020.
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2020HRIpioneers-abstract" role="button" aria-expanded="false" aria-controls="bobu2020HRIpioneers-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/lumos/bobu2020HRIpioneers.pdf" target="_blank">PDF</a>

      </div>


      <div class="col mt-2 p-0">
        <div id="bobu2020HRIpioneers-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Reinforcement learning (RL) has achieved tremendous success as a general framework for learning how to make decisions. However, this success relies on the interactive hand-tuning of a reward function by RL experts. On the other hand, inverse reinforcement learning (IRL) seeks to learn a reward function from readily-obtained human demonstrations. Yet, IRL suffers from two major limitations: 1)reward ambiguity – there are an infinite number of possible re-ward functions that could explain an expert’s demonstration and 2) heterogeneity-human experts adopt varying strategies and preferences, which makes learning from multiple demonstrators difficult due to the common assumption that demonstrators seeks to maximize the same reward. In this work, we propose a method to jointly infer a task goal and humans’ strategic preferences via network distillation. This approach enables us to distill a robust task reward (addressing reward ambiguity) and to model each strategy’s objective (handling heterogeneity). We demonstrate our algorithm can better recover task reward and strategy rewards and imitate the strategies two simulated tasks and a real-world table tennis task.
          </div>
        </div>
      </div>

    </div>
  </div>
</div>
</li>

      </ol>

			
			
			</ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2019</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">

		<li><div class="row m-0 mt-3 p-0">
			 <div class="col-sm-1 p-0 abbr">
        <a class="badge font-weight-bold pink darken-1 align-middle" style="width: 65px;" href="https://www.ieee-ras.org/publications/t-ro" target="_blank">
          HRI
        </a>
			</div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">

    <div id="bobu2019TRO" class="col p-0">
      <h5 class="title mb-0">Heterogeneous Learning from Demonstration</h5>
      <div class="author">

									<nobr><em>Rohan Paleja</em>,</nobr>

									and

                  <nobr><a href="https://core-robotics.gatech.edu/people/matthew-gombolay/" target="_blank">Matthew Gombolay</a>.</nobr>

      </div>

      <div>
        <p class="periodical font-italic">
           International Conference on Human Robot Interaction (HRI) Pioneers Workshop
        </p>
      </div>

      <div class="col p-0">

          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#bobu2019TRO-abstract" role="button" aria-expanded="false" aria-controls="bobu2019TRO-abstract">Abstract</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/lumos/bobu2019TRO.pdf" target="_blank">PDF</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/andreea7b/jaco_learning" target="_blank">Code</a>
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/lumos/bobu2019TRO_poster.pdf" target="_blank">Poster</a>

      </div>

      <div class="col mt-2 p-0">
        <div id="bobu2019TRO-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            The development of human-robot systems able to leverage the strengths of both humans and their robotic counterparts has been greatly sought after because of the foreseen, broad-ranging impact across industry and research. We believe the true potential of these systems cannot be reached unless the robot is able to act with a high level of autonomy, reducing the burden of manual tasking or teleoperation. To achieve this level of autonomy, robots must be able to work fluidly with its human partners, inferring their needs without explicit commands. This inference requires the robot to be able to detect and classify the heterogeneity of its partners. We propose a framework for learning from heterogeneous demonstration based upon Bayesian inference and evaluate a suite of approaches on a real-world dataset of gameplay from StarCraft II. This evaluation provides evidence that our Bayesian approach can outperform conventional methods by up to 12.8%.
          </div>
        </div>
      </div>

    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>


  <!-- Footer -->
  <footer>
    &copy; Copyright 2020 Rohan Paleja.
    
    
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
